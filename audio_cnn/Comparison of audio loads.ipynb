{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python audio load\n",
    "\n",
    "There are several ways to read audio files and extract the audio features in Python. This notebook focus on comparing the advantages and disadvantages of using different packages.\n",
    "\n",
    "\n",
    "### Librosa_load\n",
    "\n",
    "#### Advantages:\n",
    "1. Librosa can automatically convert the audios using different sample rate into a certain sample rate, default is 22050 Hz. \n",
    "2. Librosa also support audios using different bits\n",
    "3. Librosa converts the audio signals to float in the range of [-1, 1]\n",
    "\n",
    "#### Disadvantage:\n",
    "1. The speed is the biggest disadvantage of using the librosa_load (By testing the librosa_load on reading 1000 audios, the average loading time is 0.222 with std 0.017). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21801227474212648\n",
      "0.01819368315483547\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "time_lib = []\n",
    "audio_sample = '/efs/kevin/audio/Train/0.wav'\n",
    "\n",
    "for i in range(1000):\n",
    "    start_time = time.time()\n",
    "    signal, sample_rate = librosa.load(audio_sample)  \n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    time_lib.append(time.time() - start_time)\n",
    "\n",
    "print(np.mean(time_lib))\n",
    "print(np.std(time_lib))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By testing the librosa_load on reading 1000 audios, the average loading time is 0.222 with std 0.017). \n",
    "\n",
    "### PySoundFile\n",
    "\n",
    "#### Advantages\n",
    "1. PySoundFile can also convert the audio signals to float in the range of [-1, 1].\n",
    "2. It is much faster than the librosa package. (By testing the PySoundFile read on reading 1000 audios, the average loading time is 0.0080 with std 0.0007). \n",
    "\n",
    "#### Disadvantage:\n",
    "1. It does not support the resampling technique meaning it can not automatically convert the audios into the same sample rate. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007678573608398438\n",
      "0.0007520200370818408\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import time\n",
    "time_sf = []\n",
    "audio_sample = '/efs/kevin/audio/Train/0.wav'\n",
    "\n",
    "for i in range(1000):\n",
    "    start_time = time.time()\n",
    "    signal, sample_rate = sf.read(audio_sample)\n",
    "    signal = signal.sum(axis=1) / 2\n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    time_sf.append(time.time() - start_time)\n",
    "\n",
    "print(np.mean(time_sf))\n",
    "print(np.std(time_sf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By testing the PySoundFile on reading 1000 audios, the average loading time is 0.0080 with std 0.0007). \n",
    "\n",
    "### SciPy (not recommended) \n",
    "\n",
    "#### Advantages \n",
    "1. It is faster than Librosa but slower than PySound (By testing the PySoundFile read on reading 1000 audios, the average loading time is 0.014 with std 0.0006)\n",
    "\n",
    "#### Disadvantages\n",
    "1. Many formats are not supported. \n",
    "2. Certain metadata fields in a wav file may also lead to errors.\n",
    "3. The audio is not converted to the floate range [-1,1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014380881547927856\n",
      "0.0006542380005182429\n"
     ]
    }
   ],
   "source": [
    "import scipy.io.wavfile\n",
    "import time\n",
    "\n",
    "time_wav = []\n",
    "\n",
    "for i in range(1000):\n",
    "    audio_sample = '/efs/kevin/audio/Train/0.wav'\n",
    "    start_time = time.time()\n",
    "    sample_rate, signal = scipy.io.wavfile.read(audio_sample)  # File assumed to be in the same directory\n",
    "    signal = signal.sum(axis=1) / 2\n",
    "    norm = np.linalg.norm(signal)\n",
    "    signal = signal/norm\n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    time_wav.append(time.time() - start_time)\n",
    "    \n",
    "print(np.mean(time_wav))\n",
    "print(np.std(time_wav))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By testing the SciPy on reading 1000 audios, the average loading time is 0.014 with std 0.0006).\n",
    "\n",
    "### Numerical stability of using three methods\n",
    "\n",
    "We also compare the results generate using the three packages. Using PySoundFile generates the same results as Librosa. However, SciPy is a bit different comparing with the other two methods. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01499939 -0.02107239 -0.02680969 ...  0.01426697 -0.00772095\n",
      " -0.01293945]\n",
      "[-0.01499939 -0.02107239 -0.02680969 ...  0.01426697 -0.00772095\n",
      " -0.01293945]\n",
      "[-0.0142446  -0.02005143 -0.02553728 ...  0.01373906 -0.00728516\n",
      " -0.01227495]\n"
     ]
    }
   ],
   "source": [
    "signal, sample_rate = sf.read(audio_sample)\n",
    "signal = signal.sum(axis=1) / 2\n",
    "print(signal)\n",
    "signal, sample_rate = librosa.load(audio_sample, sample_rate)\n",
    "print(signal)\n",
    "sample_rate, signal = scipy.io.wavfile.read(audio_sample)  # File assumed to be in the same directory\n",
    "signal = signal.sum(axis=1) / 2\n",
    "signal = signal.astype(np.float32)\n",
    "signal = (signal / np.max(np.abs(signal)))\n",
    "signal -= np.mean(signal)\n",
    "signal = signal/2\n",
    "print(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Comparing the three packages, Scipy is recommended. \n",
    "\n",
    "## Python features extraction. \n",
    "\n",
    "We know librosa can help extract the features and also doing the audio augmentation. However, it is known to be slow. Here we will discuss different ways of extracting audio features.  \n",
    "\n",
    "The main sources are listed here:\n",
    "1. https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html\n",
    "2. https://python-speech-features.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import scipy.io.wavfile\n",
    "import numpy\n",
    "import time \n",
    "from scipy.fftpack import dct\n",
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012367010116577148\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "audio_sample = '/efs/kevin/audio/Train/0.wav'\n",
    "start = time.time()\n",
    "x, Fs = sf.read(audio_sample)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_speech_features\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
      "Building wheels for collected packages: python-speech-features\n",
      "  Building wheel for python-speech-features (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=4816dff088453065da8932d5caa56b12c120d23a2d55d38e6b3a319c1381ac2e\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
      "Successfully built python-speech-features\n",
      "Installing collected packages: python-speech-features\n",
      "Successfully installed python-speech-features-0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, signal = scipy.io.wavfile.read(audio_sample, 16000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[-1093,   110],\n",
       "        [-1262,  -119],\n",
       "        [-1476,  -281],\n",
       "        ...,\n",
       "        [  553,   382],\n",
       "        [ -533,    27],\n",
       "        [ -994,   146]], dtype=int16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_mfcc(audio):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sample_rate, signal = scipy.io.wavfile.read(audio_sample) \n",
    "    signal = signal.sum(axis=1) / 2\n",
    "    #norm = np.linalg.norm(signal)\n",
    "    #signal = signal/norm\n",
    "    pre_emphasis = 0.97\n",
    "    emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    res = mfcc(emphasized_signal, sample_rate)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return(res)\n",
    "    \n",
    "audio_sample = '/efs/kevin/audio/Train/0.wav'\n",
    "speech_mfcc(audio_sample)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.03383207321166992 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 16.54031732, -17.50755119, -40.50939113, ...,   6.34731066,\n",
       "          5.92619134,   7.28971799],\n",
       "       [ 16.60084093,  -7.59244194, -35.61287637, ...,  -3.76493038,\n",
       "          7.07757956,  -2.97408499],\n",
       "       [ 16.73923831, -17.80143536, -45.96136945, ...,  16.08051821,\n",
       "         10.50033786,  10.34469117],\n",
       "       ...,\n",
       "       [ 16.27960321, -17.85235779, -37.84628609, ...,  -1.32503418,\n",
       "          2.146214  ,  10.96781671],\n",
       "       [ 16.30563504, -19.54822195, -37.36319627, ...,   1.19234113,\n",
       "          0.48887082,   5.64367358],\n",
       "       [ 16.43376117, -22.6739382 , -47.26553261, ...,   9.84395669,\n",
       "         -4.61113531,   8.39586759]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_mfcc(audio, n_mfcc):\n",
    "    start_time = time.time()\n",
    "    sample_rate, signal = scipy.io.wavfile.read(audio_sample) \n",
    "    signal = signal.sum(axis=1) / 2\n",
    "    #norm = np.linalg.norm(signal)\n",
    "    #signal = signal/norm\n",
    "    pre_emphasis = 0.97\n",
    "    emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    \n",
    "    frame_size = 0.025\n",
    "    frame_stride = 0.01\n",
    "    \n",
    "    frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
    "    signal_length = len(emphasized_signal)\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "    num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = numpy.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = numpy.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "\n",
    "    indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(numpy.int32, copy=False)]\n",
    "    \n",
    "    NFFT = 512\n",
    "    frames *= numpy.hamming(frame_length)\n",
    "    mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
    "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2)) \n",
    "    \n",
    "    low_freq_mel = 0\n",
    "    num_ceps = 12\n",
    "    high_freq_mel = (2595 * numpy.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\n",
    "    mel_points = numpy.linspace(low_freq_mel, high_freq_mel, n_mfcc + 2)  # Equally spaced in Mel scale\n",
    "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "    bin = numpy.floor((NFFT + 1) * hz_points / sample_rate)\n",
    "\n",
    "    fbank = numpy.zeros((n_mfcc, int(numpy.floor(NFFT / 2 + 1))))\n",
    "    for m in range(1, n_mfcc + 1):\n",
    "        f_m_minus = int(bin[m - 1])   # left\n",
    "        f_m = int(bin[m])             # center\n",
    "        f_m_plus = int(bin[m + 1])    # right\n",
    "\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    filter_banks = numpy.dot(pow_frames, fbank.T)\n",
    "    filter_banks = numpy.where(filter_banks == 0, numpy.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "    filter_banks = 20 * numpy.log10(filter_banks)  # dB\n",
    "    \n",
    "    mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13\n",
    "    filter_banks -= (numpy.mean(filter_banks, axis=0) + 1e-8)\n",
    "    mfcc -= (numpy.mean(mfcc, axis=0) + 1e-8)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.029557228088378906 seconds ---\n"
     ]
    }
   ],
   "source": [
    "audio_sample = '/efs/kevin/audio/Train/0.wav'\n",
    "n_mfcc = 40\n",
    "fast_mfcc(audio_sample, n_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_wav = []\n",
    "time_lib = []\n",
    "\n",
    "for i in range(1000):\n",
    "    audio_sample = '/efs/kevin/audio/Train/0.wav'\n",
    "    start_time = time.time()\n",
    "    sample_rate_wav, signal_wav = scipy.io.wavfile.read(audio_sample)  # File assumed to be in the same directory\n",
    "    signal_wav = signal_wav.sum(axis=1) / 2\n",
    "    norm = np.linalg.norm(signal_wav)\n",
    "    signal_wav = signal_wav/norm\n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    time_wav.append(time.time() - start_time)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    signal, sample_rate = librosa.load(audio_sample)  # File assumed to be in the same directory\n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    time_lib.append(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012060447931289672\n",
      "0.24378951597213744\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(time_wav))\n",
    "print(np.mean(time_lib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01212928, -0.02760112, -0.02535508, ...,  0.09790608,\n",
       "        0.04330474, -0.00681015], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01212928, -0.02760112, -0.02535508, ...,  0.09790608,\n",
       "        0.04330474, -0.00681015], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-491.5, -690.5, -878.5, ...,  467.5, -253. , -424. ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
